{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python388jvsc74a57bd083a57f94260e95a4e45916b37da563823ce82fbf9f4555f81ec33dec4a2a6d7c",
      "display_name": "Python 3.8.8 64-bit ('cv_analyser': conda)"
    },
    "colab": {
      "name": "bow_model_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TrF3jLo-a1j",
        "outputId": "2d0d3163-f4c8-43db-f15b-5c367e99d34b"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8N5u6se-mZR",
        "outputId": "8daea115-f132-4dc6-8862-67de18dfcb07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSXo0L9f-a1n"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWeeCmqm-a1t"
      },
      "source": [
        "os.chdir('/gdrive/My Drive/drivebuddy_text_classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh_eDrAD-a1q"
      },
      "source": [
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsCZbO56-a1v"
      },
      "source": [
        "def filter_query(query):\n",
        "    query = query.lower()\n",
        "    query = re.sub(r'[@][^\\s]+', '', query)\n",
        "    query = re.sub(r'pav.{0,3}bhaji', ' pavbhaji ', query)\n",
        "    query = re.sub(r'[\\!-\\/\\:-\\@]+', ' ', query)\n",
        "    query = re.sub('[^A-Za-z0-9\\s]+', ' ', query)\n",
        "    query = re.sub(r'[\\t\\n\\r\\f ]+', ' ', re.sub(r'\\.', '. ', query))\n",
        "    query = ' '.join([w for w in query.split() if w not in stopwords.words('english')])\n",
        "    \n",
        "    # print (query)\n",
        "    # doc = nlp(query)\n",
        "    # tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    # filt_q = ' '.join(tokens)\n",
        "    filt_q = re.sub(r'\\b(n\\'t|nt)\\b', 'not', query)\n",
        "    filt_q = re.sub(r'\\'ll\\b', 'will', filt_q)\n",
        "    return filt_q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb5jze5L4UpK",
        "outputId": "f3b90413-8617-4930-f61d-0ca47d45aa49"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7RuWmqg-a1v"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umoikyhe-a1w"
      },
      "source": [
        "with open('dataset_mod/pavbhaji.json', 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1a0QkRK-a1x"
      },
      "source": [
        "# indexing json data with filename\n",
        "indexed_data = {d['display_url'].split('/')[-1]: d['edge_media_to_caption']['edges'][0]['node']['text'] for d in data if d['edge_media_to_caption']['edges']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCz8z2uf-a1x"
      },
      "source": [
        "file_names0_set = set([f.split('/')[-1] for f in glob.glob('dataset_mod/images/0/*.jpg')])\n",
        "file_names1_set = set([f.split('/')[-1] for f in glob.glob('dataset_mod/images/1/*.jpg')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m90_64RB-a1z"
      },
      "source": [
        "# dataframe with columns (filename, text, label)\n",
        "data_with_labels = pd.DataFrame([{'name': name, 'text': indexed_data[name], 'label': 1 if name in file_names1_set else 0} for name in file_names0_set | file_names1_set])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJIxs6Vh-a11"
      },
      "source": [
        "processed_text = data_with_labels['text'].map(filter_query)\n",
        "df = pd.DataFrame({'name':data_with_labels['name'], 'text':processed_text, 'label': data_with_labels['label']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVVIHzq-a12"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MRNcfQB-a13"
      },
      "source": [
        "# creating BOW model with ngrams lengths ranging from 1 to 5 tokens\n",
        "bow_vector = CountVectorizer(tokenizer=word_tokenize, ngram_range=(1,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsSne4AZ-a2M"
      },
      "source": [
        "classifier = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRDH2O3O-a2M"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', bow_vector), ('classifier', classifier)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLYaDQtq-a2N",
        "outputId": "97c393f0-bdb8-4c18-e89e-56231aa30255"
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 5), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word_tokenize at 0x7f5cbb5d47a0>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqVoVSyF-a2O",
        "outputId": "8ce4abc2-aa40-4526-e1ae-c73ad085304b"
      },
      "source": [
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 72% achieved\n",
        "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
        "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.7252747252747253\n",
            "Logistic Regression Precision: 0.6326530612244898\n",
            "Logistic Regression Recall: 0.8157894736842105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp4C5bXt-a2P"
      },
      "source": [
        "# using multi layer perceptron classifier model\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(16, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXPkZOm5-a2P"
      },
      "source": [
        "pipe1 = Pipeline([('vectorizer', bow_vector), ('classifier', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqBG2W5w-a2Q",
        "outputId": "bb792ccd-fbea-4e3c-9e48-e3d8653cf7bb"
      },
      "source": [
        "pipe1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 5), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(16, 8),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='lbfgs',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdmc6agA-a2Q",
        "outputId": "d0e53a4e-ba47-4a04-e0d0-53d94c07f554"
      },
      "source": [
        "predicted = pipe1.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 69% achieved\n",
        "print(\"MLP Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP Accuracy: 0.6923076923076923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB9COFQM-a2Q"
      },
      "source": [
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(64, 64) )\n",
        "# clf = MLPClassifier(solver='adam', \n",
        "#                       hidden_layer_sizes=(64, 64), \n",
        "#                       learning_rate='adaptive', \n",
        "#                       max_iter=1000, \n",
        "#                       early_stopping=True, \n",
        "#                       n_iter_no_change=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOJMtg0I-a2R"
      },
      "source": [
        "pipe1 = Pipeline([('vectorizer', bow_vector), ('classifier', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwP-KZ_P-a2R",
        "outputId": "f500f220-46e0-4ba4-a3b0-7de03b959af1"
      },
      "source": [
        "pipe1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 5), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(64, 64),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='lbfgs',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4OBlc-x-a2R",
        "outputId": "4f43191f-cc3b-425b-9648-ce6f80aa0f52"
      },
      "source": [
        "predicted = pipe1.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 72% achieved\n",
        "print(\"MLP Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP Regression Accuracy: 0.7252747252747253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZX4lEAl-a2S"
      },
      "source": [
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(128, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPixXgnH-a2S"
      },
      "source": [
        "pipe1 = Pipeline([('vectorizer', bow_vector), ('classifier', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-0e4Dw-a2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4404d6c2-eda0-41fb-e78b-75d7c4f3c5cb"
      },
      "source": [
        "pipe1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 5), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(128, 64),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='lbfgs',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spuRPrHh-a2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89134941-7d79-4107-8b45-18622b31e6a6"
      },
      "source": [
        "predicted = pipe1.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 71% achieved\n",
        "print(\"MLP Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP Accuracy: 0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoGUyU2A-a2X"
      },
      "source": [
        "# BOW vectorizer with ngrams range of 1 to 3\n",
        "bow_vector = CountVectorizer(tokenizer=word_tokenize, ngram_range=(1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKBpqK6P-a2Y"
      },
      "source": [
        "pipe1 = Pipeline([('vectorizer', bow_vector), ('classifier', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCAzTKm-a2Y",
        "outputId": "47d7351a-3899-46e3-a407-716b716f53d4"
      },
      "source": [
        "pipe1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(128, 64),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='lbfgs',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgj7RBjq-a2Z",
        "outputId": "a2ac1cb6-8821-4e05-c188-ab28b7030baa"
      },
      "source": [
        "predicted = pipe1.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 73% aqchieved\n",
        "print(\"MLP Accuracy:\", metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP Accuracy: 0.7362637362637363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnuKqae6MvwQ",
        "outputId": "59493411-227d-4170-b87b-3e7d4cd9410f"
      },
      "source": [
        "# trying out a simpler model\n",
        "clf_tree = DecisionTreeClassifier()\n",
        "\n",
        "pipe_tree = Pipeline([('vectorizer', bow_vector), ('classifier', clf_tree)])\n",
        "\n",
        "pipe_tree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function word...0>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features=None, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort='deprecated', random_state=None,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up2Y3L1YMvwQ",
        "outputId": "6c794418-167f-4a43-cf6e-14edd2e73fee"
      },
      "source": [
        "predicted = pipe_tree.predict(X_test)\n",
        "\n",
        "# Model Accuracy of 65% achieved\n",
        "print(\"Decision Tree Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy: 0.6593406593406593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC2m9PC1-a2b"
      },
      "source": [
        "# BOW vectorizer with ngrams ranging from 1 to 5\n",
        "bow_vectorizer = CountVectorizer(tokenizer=word_tokenize, ngram_range=(1,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS6Ng8dD-a2b",
        "outputId": "ce0b2bc2-f83e-45b3-f9e4-d56d2287fb56"
      },
      "source": [
        "bow_vectorizer.fit(df['text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 5), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=<function word_tokenize at 0x7f5cbb5d47a0>,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGTSmdmy-a2c"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def create_ngram_with_position(text, n):\n",
        "    # tokens = tokenize_hing(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    position_dict = {} # vocab_ind: position\n",
        "    for i in range(n):\n",
        "        for j in range(len(tokens) - i):\n",
        "            vocab_ind = bow_vectorizer.vocabulary_[' '.join(tokens[j : j + 1 + i])]\n",
        "            if vocab_ind not in position_dict:\n",
        "                position_dict.update({vocab_ind: j})\n",
        "    return position_dict\n",
        "\n",
        "# function to vectorize text with the position of the element in the vocabulary index\n",
        "# this will help to capture relative positional information to try and classify the data points\n",
        "def transform_position_vector(text_series, ngram_size):\n",
        "    row = []\n",
        "    col = []\n",
        "    mat_data = []\n",
        "    for i, t in enumerate(text_series):\n",
        "        position_dict = create_ngram_with_position(t, ngram_size)\n",
        "        for ind, pos in position_dict.items():\n",
        "            row.append(i)\n",
        "            col.append(ind)\n",
        "            mat_data.append(pos)\n",
        "    return csr_matrix((mat_data, (row, col)), shape=(len(text_series), len(bow_vectorizer.vocabulary_)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APr8vE2t-a2c",
        "outputId": "250a81cb-0d40-4849-b059-e90d823a4606"
      },
      "source": [
        "print (transform_position_vector(df['text'][0:3], 5)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 3598)\t4\n",
            "  (0, 3599)\t10\n",
            "  (0, 3600)\t10\n",
            "  (0, 3601)\t10\n",
            "  (0, 3602)\t10\n",
            "  (0, 3603)\t4\n",
            "  (0, 3604)\t4\n",
            "  (0, 3605)\t4\n",
            "  (0, 3606)\t4\n",
            "  (0, 7568)\t8\n",
            "  (0, 7569)\t8\n",
            "  (0, 7570)\t8\n",
            "  (0, 7571)\t8\n",
            "  (0, 7572)\t8\n",
            "  (0, 7623)\t21\n",
            "  (0, 7636)\t21\n",
            "  (0, 7637)\t21\n",
            "  (0, 7638)\t21\n",
            "  (0, 7639)\t21\n",
            "  (0, 8154)\t11\n",
            "  (0, 8155)\t11\n",
            "  (0, 8156)\t11\n",
            "  (0, 8157)\t11\n",
            "  (0, 8158)\t11\n",
            "  (0, 8298)\t15\n",
            "  :\t:\n",
            "  (0, 31443)\t26\n",
            "  (0, 31565)\t9\n",
            "  (0, 31566)\t9\n",
            "  (0, 31567)\t9\n",
            "  (0, 31568)\t9\n",
            "  (0, 31569)\t9\n",
            "  (0, 35111)\t1\n",
            "  (0, 35112)\t1\n",
            "  (0, 35113)\t1\n",
            "  (0, 35114)\t1\n",
            "  (0, 35115)\t1\n",
            "  (0, 36592)\t2\n",
            "  (0, 37581)\t6\n",
            "  (0, 37582)\t6\n",
            "  (0, 37583)\t6\n",
            "  (0, 37584)\t6\n",
            "  (0, 37827)\t2\n",
            "  (0, 37831)\t2\n",
            "  (0, 37832)\t2\n",
            "  (0, 37833)\t2\n",
            "  (0, 47967)\t0\n",
            "  (0, 48005)\t0\n",
            "  (0, 48006)\t0\n",
            "  (0, 48007)\t0\n",
            "  (0, 48008)\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovuQ5c9w-a2d"
      },
      "source": [
        "X_train_mat = transform_position_vector(X_train, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1G1kzOW-a2e"
      },
      "source": [
        "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(64, 64), learning_rate='adaptive', max_iter=1000, early_stopping=True, n_iter_no_change=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fWZsV9a-a2e",
        "outputId": "3efc859d-a9d8-4148-dbe4-12819525285d"
      },
      "source": [
        "clf.fit(X_train_mat.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(64, 64), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=20, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_ocL1r0-a2e"
      },
      "source": [
        "X_test_mat = transform_position_vector(X_test, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZDgc-S7-a2e",
        "outputId": "c292bd8b-eb59-49f9-bcba-26cc3995aa61"
      },
      "source": [
        "predicted = clf.predict(X_test_mat.toarray())\n",
        "\n",
        "# Model Accuracy of 69% achieved\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6923076923076923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSGpTM2KsFe",
        "outputId": "58a7a65c-d38a-48f3-9e2a-1ae90fdba843"
      },
      "source": [
        "clf_tree = DecisionTreeClassifier()\n",
        "clf_tree.fit(X_train_mat.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSrGgK2OK9mg",
        "outputId": "ca0e145d-844c-4a21-98a3-30740f5fbde7"
      },
      "source": [
        "predicted = clf_tree.predict(X_test_mat.toarray())\n",
        "\n",
        "# Model Accuracy of 68% achieved\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6813186813186813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WV4_9kgG1XJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "# import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, Layer, concatenate, Concatenate, Reshape, Conv2D, Conv1D, Masking\n",
        "from tensorflow.keras.models import Model, load_model, model_from_json\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_hub as hub\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcOUb1gnH-X3"
      },
      "source": [
        "# implementing a dense layer for positional features using keras\n",
        "\n",
        "input_vect = Input(shape=(len(bow_vectorizer.vocabulary_),), dtype=tf.int64)\n",
        "# embedding = Lambda(transform_position_vector,output_shape=(embed_size,))(input_text)\n",
        "dense1 = Dense(128, activation='relu')(input_vect)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "out = Dense(1, activation='sigmoid')(dense2)\n",
        "model = Model(inputs=[input_vect], outputs=out)\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "optimizer = Adam(lr=LEARNING_RATE)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D_M2pxgIb_F"
      },
      "source": [
        "\n",
        "class LearningRateTracker(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\" - lr: {}\".format(K.eval(self.model.optimizer.lr))) \n",
        "\n",
        "LR_PATIENCE = 10\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=LR_PATIENCE, min_lr=1e-8, verbose=1, mode=\"min\")\n",
        "es_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "lr_tracker = LearningRateTracker()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBKcm6a7Igvz",
        "outputId": "e9fe4779-ac62-4044-ba2a-9a975dfbb65d"
      },
      "source": [
        "history = model.fit(X_train_mat.toarray(), \n",
        "          y_train,\n",
        "          validation_data=(X_test_mat.toarray(), y_test),\n",
        "          epochs=1000,\n",
        "          batch_size=256,\n",
        "          callbacks=[es_callback, lr_tracker, reduce_lr])\n",
        "\n",
        "# achieved accuracy of 74.7%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 0.8228 - accuracy: 0.5490 - val_loss: 0.6157 - val_accuracy: 0.7143\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.1333 - accuracy: 0.9837 - val_loss: 0.6988 - val_accuracy: 0.7143\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 214ms/step - loss: 0.0946 - accuracy: 0.9887 - val_loss: 0.8006 - val_accuracy: 0.7033\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.0885 - accuracy: 0.9874 - val_loss: 0.8665 - val_accuracy: 0.7033\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.0804 - accuracy: 0.9900 - val_loss: 0.9145 - val_accuracy: 0.7143\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 189ms/step - loss: 0.0746 - accuracy: 0.9874 - val_loss: 0.9645 - val_accuracy: 0.7253\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 188ms/step - loss: 0.0714 - accuracy: 0.9874 - val_loss: 1.0097 - val_accuracy: 0.7143\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 0.0605 - accuracy: 0.9887 - val_loss: 1.0514 - val_accuracy: 0.7143\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 0.0618 - accuracy: 0.9887 - val_loss: 1.0901 - val_accuracy: 0.7253\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 193ms/step - loss: 0.0563 - accuracy: 0.9913 - val_loss: 1.1253 - val_accuracy: 0.7253\n",
            " - lr: 0.0010000000474974513\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.0568 - accuracy: 0.9887 - val_loss: 1.1561 - val_accuracy: 0.7253\n",
            " - lr: 0.0010000000474974513\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.0551 - accuracy: 0.9900 - val_loss: 1.1619 - val_accuracy: 0.7253\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.0550 - accuracy: 0.9874 - val_loss: 1.1669 - val_accuracy: 0.7253\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 1.1716 - val_accuracy: 0.7253\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 0.0509 - accuracy: 0.9913 - val_loss: 1.1758 - val_accuracy: 0.7253\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 194ms/step - loss: 0.0515 - accuracy: 0.9900 - val_loss: 1.1796 - val_accuracy: 0.7253\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 0.0520 - accuracy: 0.9900 - val_loss: 1.1832 - val_accuracy: 0.7473\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.0520 - accuracy: 0.9887 - val_loss: 1.1864 - val_accuracy: 0.7473\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 211ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 1.1895 - val_accuracy: 0.7473\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 0.0525 - accuracy: 0.9887 - val_loss: 1.1925 - val_accuracy: 0.7473\n",
            " - lr: 0.00020000000949949026\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.0490 - accuracy: 0.9900 - val_loss: 1.1956 - val_accuracy: 0.7473\n",
            " - lr: 0.00020000000949949026\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 193ms/step - loss: 0.0463 - accuracy: 0.9900 - val_loss: 1.1962 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 0.0503 - accuracy: 0.9887 - val_loss: 1.1968 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.0526 - accuracy: 0.9887 - val_loss: 1.1974 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 197ms/step - loss: 0.0494 - accuracy: 0.9887 - val_loss: 1.1981 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 0.0527 - accuracy: 0.9887 - val_loss: 1.1987 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 0.0506 - accuracy: 0.9887 - val_loss: 1.1993 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.0511 - accuracy: 0.9900 - val_loss: 1.1999 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 188ms/step - loss: 0.0493 - accuracy: 0.9874 - val_loss: 1.2005 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 222ms/step - loss: 0.0466 - accuracy: 0.9900 - val_loss: 1.2012 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 222ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 1.2020 - val_accuracy: 0.7473\n",
            " - lr: 4.0000002627493814e-05\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 0.0495 - accuracy: 0.9887 - val_loss: 1.2021 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 0.0462 - accuracy: 0.9900 - val_loss: 1.2023 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 1.2024 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 1.2026 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 188ms/step - loss: 0.0507 - accuracy: 0.9887 - val_loss: 1.2028 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 197ms/step - loss: 0.0500 - accuracy: 0.9900 - val_loss: 1.2029 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 190ms/step - loss: 0.0534 - accuracy: 0.9887 - val_loss: 1.2031 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 0.0519 - accuracy: 0.9900 - val_loss: 1.2033 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 208ms/step - loss: 0.0508 - accuracy: 0.9874 - val_loss: 1.2034 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.0522 - accuracy: 0.9900 - val_loss: 1.2036 - val_accuracy: 0.7473\n",
            " - lr: 8.000000889296643e-06\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 0.0480 - accuracy: 0.9900 - val_loss: 1.2036 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 0.0490 - accuracy: 0.9900 - val_loss: 1.2036 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 0.0492 - accuracy: 0.9900 - val_loss: 1.2037 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 216ms/step - loss: 0.0492 - accuracy: 0.9874 - val_loss: 1.2037 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 201ms/step - loss: 0.0511 - accuracy: 0.9887 - val_loss: 1.2037 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 1.2037 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 209ms/step - loss: 0.0480 - accuracy: 0.9900 - val_loss: 1.2038 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.0468 - accuracy: 0.9900 - val_loss: 1.2038 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 0.0515 - accuracy: 0.9874 - val_loss: 1.2039 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 198ms/step - loss: 0.0500 - accuracy: 0.9900 - val_loss: 1.2039 - val_accuracy: 0.7473\n",
            " - lr: 1.6000001323845936e-06\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}